{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading facebook dataset ...\n",
      "Train= (30712, 52)\n",
      "Kaggle= (10237, 52)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import kaggle\n",
    "import timeit\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "\n",
    "# Read in train and test data\n",
    "\n",
    "def read_data_fb():\n",
    "\tprint('Reading facebook dataset ...')\n",
    "\ttrain_x = np.loadtxt('../../Data/data.csv', delimiter=',')\n",
    "\ttrain_y = np.loadtxt('../../Data/labels.csv', delimiter=',')\n",
    "\ttrain_kaggle = np.loadtxt('../../Data/kaggle_data.csv', delimiter=',')\n",
    "\n",
    "\treturn (train_x, train_y, train_kaggle)\n",
    "\n",
    "# Compute MAE\n",
    "def compute_error(y_hat, y):\n",
    "\t# mean absolute error\n",
    "\treturn np.abs(y_hat - y).mean()\n",
    "\n",
    "############################################################################\n",
    "\n",
    "train_x, train_y, kaggle_x   = read_data_fb()\n",
    "print('Train=', train_x.shape)\n",
    "print('Kaggle=', kaggle_x.shape)\n",
    "\n",
    "\n",
    "\n",
    "######### normalizing features to speed up SVM, we shouldn't normalize outputs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_x2=StandardScaler().fit_transform(train_x)\n",
    "kaggle_x2=StandardScaler().fit_transform(kaggle_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with CV on SVM\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "######### normalizing features to speed up SVM, we shouldn't normalize outputs\n",
    "train_x2=StandardScaler().fit_transform(train_x)\n",
    "kaggle_x2=StandardScaler().fit_transform(kaggle_x)\n",
    "\n",
    "mysvr = SVR(kernel='poly') \n",
    "p_grid = {'degree':[1,2]}\n",
    "bestsvr1 = GridSearchCV(estimator=mysvr, param_grid=p_grid, cv=5,return_train_score=True,scoring='neg_mean_absolute_error')\n",
    "bestsvr1.fit(train_x2,train_y)\n",
    "print(\"Done with CV on Polynomial SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of sample errors for polynomial SVM: [ 5.45863541  6.02130429]\n",
      "degree of the polynomial [1, 2]\n"
     ]
    }
   ],
   "source": [
    "print('out of sample errors for polynomial SVM:', abs(bestsvr1.cv_results_['mean_test_score']))\n",
    "print('degree of the polynomial', [1,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with CV on RBF SVM\n",
      "out of sample errors for RBF SVM: [ 5.76267034]\n"
     ]
    }
   ],
   "source": [
    "mysvr2 = SVR()\n",
    "p_grid = {'kernel': ['rbf']}\n",
    "bestsvr2 = GridSearchCV(estimator=mysvr2, param_grid=p_grid, cv=5,return_train_score=True,scoring='neg_mean_absolute_error')\n",
    "bestsvr2.fit(train_x2,train_y)\n",
    "print(\"Done with CV on RBF SVM\")\n",
    "print('out of sample errors for RBF SVM:', abs(bestsvr2.cv_results_['mean_test_score']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with CV on RBF SVM\n",
      "out of sample errors for RBF SVM: 5.76265710611\n",
      "scores [-5.50482684 -6.42699884 -5.44142722 -6.36426978 -5.07576285]\n"
     ]
    }
   ],
   "source": [
    "# This cell does the same thing as the above cell\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svr3 = SVR(kernel='rbf')\n",
    "scores = cross_val_score(svr3, train_x2, train_y, cv=5,scoring='neg_mean_absolute_error')\n",
    "print(\"Done with CV on RBF SVM\")\n",
    "print('out of sample errors for RBF SVM:', abs((scores.mean())))\n",
    "print('scores',scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing output to  ../Predictions/bestsvr.csv\n",
      "Done with writing.\n"
     ]
    }
   ],
   "source": [
    "bestsvr=SVR(kernel='poly',degree=1)\n",
    "bestsvr.fit(train_x2,train_y)\n",
    "predicted_y=bestsvr.predict(kaggle_x2)\n",
    "file_name = '../Predictions/bestsvr.csv'\n",
    "# Writing output in Kaggle format\n",
    "print('Writing output to ', file_name)\n",
    "kaggle.kaggleize(predicted_y, file_name)\n",
    "print('Done with writing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "mysvr = SVR(kernel='poly') \n",
    "p_grid = {'degree':[1,3,4,5]}\n",
    "bestsvr1 = GridSearchCV(estimator=mysvr, param_grid=p_grid, cv=5,return_train_score=True,scoring='neg_mean_absolute_error')\n",
    "bestsvr1.fit(train_x2,train_y)\n",
    "print(\"Done with CV on Polynomial SVM\")\n",
    "print('out of sample errors for polynomial SVM:', abs(bestsvr1.cv_results_['mean_test_score']))\n",
    "print('degree of the polynomial', [1,3,4,5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with CV on NN\n"
     ]
    }
   ],
   "source": [
    "### Question 5\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "mynn=MLPRegressor(max_iter=400)\n",
    "p_grid = {'hidden_layer_sizes':[(10,),(20,),(30,),(40,)]}\n",
    "#p_grid = {'hidden_layer_sizes':[(20,)]}\n",
    "bestnn = GridSearchCV(estimator=mynn, param_grid=p_grid, cv=5,return_train_score=True,scoring='neg_mean_absolute_error')\n",
    "bestnn.fit(train_x2,train_y)\n",
    "print(\"Done with CV on NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_layer_sizes': (10,)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestnn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of sample errors for NN [ 6.6604514   7.22658936  7.21928379  7.16788212]\n",
      "number of neurons in the single hidden layer: [10, 20, 30, 40]\n"
     ]
    }
   ],
   "source": [
    "print('out of sample errors for NN', abs(bestnn.cv_results_['mean_test_score']))\n",
    "print('number of neurons in the single hidden layer:', [10,20,30,40])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing output to  ../Predictions/bestnn.csv\n",
      "Done with writing.\n"
     ]
    }
   ],
   "source": [
    "bestnn.fit(train_x2,train_y)\n",
    "predicted_y=bestnn.predict(kaggle_x2)\n",
    "file_name = '../Predictions/bestnn.csv'\n",
    "# Writing output in Kaggle format\n",
    "print('Writing output to ', file_name)\n",
    "kaggle.kaggleize(predicted_y, file_name)\n",
    "print('Done with writing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of sample errors: [ 5.42975997  5.42975997  5.42975997  4.96189596  4.92476486  4.90516589\n",
      "  4.95768042  4.9232807   4.8759661   5.0742309   5.02391522  5.07945346\n",
      "  5.12638377  5.16033442  5.21296676]\n",
      "max depth: [3, 6, 9]\n",
      "Error from CV: 4.87596610142\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "mytree = tree.DecisionTreeRegressor()\n",
    "p_grid = {'max_depth':[4,6,8,10,12],'min_samples_split' :[2,3,4]}\n",
    "besttree = GridSearchCV(estimator=mytree, param_grid=p_grid, cv=5,return_train_score=True,scoring='neg_mean_absolute_error')\n",
    "besttree.fit(train_x2,train_y)\n",
    "print('out of sample errors:', abs(besttree.cv_results_['mean_test_score']))\n",
    "print('max depth:', [3,6,9])\n",
    "print('Error from CV:',(besttree.cv_results_['mean_test_score'].max())*(-1))\n",
    "#predicted_y=besttree.predict(kaggle_x2)\n",
    "#file_name = '../Predictions/bestbest.csv'\n",
    "#kaggle.kaggleize(predicted_y, file_name)\n",
    "#print('Done with writing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with writing.\n"
     ]
    }
   ],
   "source": [
    "predicted_y=besttree.predict(kaggle_x2)\n",
    "file_name = '../Predictions/bestbest.csv'\n",
    "kaggle.kaggleize(predicted_y, file_name)\n",
    "print('Done with writing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of sample errors: [ 5.44213487]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "myregr = LinearSVR()\n",
    "p_grid = {'random_state':[0]}\n",
    "bestsv = GridSearchCV(estimator=myregr, param_grid=p_grid, cv=5,return_train_score=True,scoring='neg_mean_absolute_error')\n",
    "bestsv.fit(train_x2,train_y)\n",
    "print('out of sample errors:', abs(bestsv.cv_results_['mean_test_score']))\n",
    "#predicted_y=besttree.predict(kaggle_x2)\n",
    "#file_name = '../Predictions/bestbest.csv'\n",
    "#kaggle.kaggleize(predicted_y, file_name)\n",
    "#print('Done with writing.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with writing.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predicted_y=besttree.predict(kaggle_x2)\n",
    "file_name = '../Predictions/bestbest.csv'\n",
    "kaggle.kaggleize(predicted_y, file_name)\n",
    "print('Done with writing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=1, epsilon=0.1, gamma='auto',\n",
       "  kernel='poly', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "bestsvr=SVR(kernel='poly',degree=1)\n",
    "bestsvr.fit(train_x2,train_y)\n",
    "#predicted_y=bestsvr.predict(kaggle_x2)\n",
    "#file_name = '../Predictions/bestbest.csv'\n",
    "# Writing output in Kaggle format\n",
    "#print('Writing output to ', file_name)\n",
    "#kaggle.kaggleize(predicted_y, file_name)\n",
    "#print('Done with writing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.816890637773882"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "al=bestsvr.predict(train_x2)\n",
    "al.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.4260660692995613"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_error(al.clip(min=0), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing output to  ../Predictions/bestbest.csv\n",
      "Done with writing.\n"
     ]
    }
   ],
   "source": [
    "predicted_y=bestsvr.predict(kaggle_x2)\n",
    "predicted_y=predicted_y.clip(min=0)\n",
    "file_name = '../Predictions/bestbest.csv'\n",
    "# Writing output in Kaggle format\n",
    "print('Writing output to ', file_name)\n",
    "kaggle.kaggleize(predicted_y, file_name)\n",
    "print('Done with writing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1305.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334.56982304752671"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "al.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433.5991448456964"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.435855691586351"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22c54d04c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "30712/30712 [==============================] - 2s 55us/step - loss: 7.4359\n",
      "Epoch 2/200\n",
      "30712/30712 [==============================] - 1s 45us/step - loss: 7.4359\n",
      "Epoch 3/200\n",
      "30712/30712 [==============================] - 1s 45us/step - loss: 7.4359\n",
      "Epoch 4/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 5/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 6/200\n",
      "30712/30712 [==============================] - 1s 45us/step - loss: 7.4359\n",
      "Epoch 7/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 8/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 9/200\n",
      "30712/30712 [==============================] - 1s 47us/step - loss: 7.4359\n",
      "Epoch 10/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 11/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 12/200\n",
      "30712/30712 [==============================] - 1s 42us/step - loss: 7.4359\n",
      "Epoch 13/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 14/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 15/200\n",
      "30712/30712 [==============================] - 1s 42us/step - loss: 7.4359\n",
      "Epoch 16/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 17/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 18/200\n",
      "30712/30712 [==============================] - 1s 42us/step - loss: 7.4359\n",
      "Epoch 19/200\n",
      "30712/30712 [==============================] - 1s 42us/step - loss: 7.4359\n",
      "Epoch 20/200\n",
      "30712/30712 [==============================] - 1s 45us/step - loss: 7.4359\n",
      "Epoch 21/200\n",
      "30712/30712 [==============================] - 1s 41us/step - loss: 7.4359\n",
      "Epoch 22/200\n",
      "30712/30712 [==============================] - 1s 42us/step - loss: 7.4359\n",
      "Epoch 23/200\n",
      "30712/30712 [==============================] - 1s 41us/step - loss: 7.4359\n",
      "Epoch 24/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 25/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 26/200\n",
      "30712/30712 [==============================] - 1s 39us/step - loss: 7.4359\n",
      "Epoch 27/200\n",
      "30712/30712 [==============================] - 1s 41us/step - loss: 7.4359\n",
      "Epoch 28/200\n",
      "30712/30712 [==============================] - 2s 51us/step - loss: 7.4359\n",
      "Epoch 29/200\n",
      "30712/30712 [==============================] - 2s 58us/step - loss: 7.4359\n",
      "Epoch 30/200\n",
      "30712/30712 [==============================] - 2s 49us/step - loss: 7.4359\n",
      "Epoch 31/200\n",
      "30712/30712 [==============================] - 2s 50us/step - loss: 7.4359\n",
      "Epoch 32/200\n",
      "30712/30712 [==============================] - 1s 41us/step - loss: 7.4359\n",
      "Epoch 33/200\n",
      "30712/30712 [==============================] - 1s 46us/step - loss: 7.4359\n",
      "Epoch 34/200\n",
      "30712/30712 [==============================] - 1s 46us/step - loss: 7.4359\n",
      "Epoch 35/200\n",
      "30712/30712 [==============================] - 1s 45us/step - loss: 7.4359\n",
      "Epoch 36/200\n",
      "30712/30712 [==============================] - 1s 47us/step - loss: 7.4359\n",
      "Epoch 37/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 38/200\n",
      "30712/30712 [==============================] - 1s 41us/step - loss: 7.4359\n",
      "Epoch 39/200\n",
      "30712/30712 [==============================] - 1s 39us/step - loss: 7.4359\n",
      "Epoch 40/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 41/200\n",
      "30712/30712 [==============================] - 1s 47us/step - loss: 7.4359\n",
      "Epoch 42/200\n",
      "30712/30712 [==============================] - 1s 38us/step - loss: 7.4359\n",
      "Epoch 43/200\n",
      "30712/30712 [==============================] - 1s 38us/step - loss: 7.4359\n",
      "Epoch 44/200\n",
      "30712/30712 [==============================] - 1s 39us/step - loss: 7.4359\n",
      "Epoch 45/200\n",
      "30712/30712 [==============================] - 1s 38us/step - loss: 7.4359\n",
      "Epoch 46/200\n",
      "30712/30712 [==============================] - 1s 39us/step - loss: 7.4359\n",
      "Epoch 47/200\n",
      "30712/30712 [==============================] - 1s 37us/step - loss: 7.4359\n",
      "Epoch 48/200\n",
      "30712/30712 [==============================] - 1s 40us/step - loss: 7.4359\n",
      "Epoch 49/200\n",
      "30712/30712 [==============================] - 1s 40us/step - loss: 7.4359\n",
      "Epoch 50/200\n",
      "30712/30712 [==============================] - 1s 40us/step - loss: 7.4359\n",
      "Epoch 51/200\n",
      "30712/30712 [==============================] - 1s 38us/step - loss: 7.4359\n",
      "Epoch 52/200\n",
      "30712/30712 [==============================] - 1s 38us/step - loss: 7.4359\n",
      "Epoch 53/200\n",
      "30712/30712 [==============================] - 1s 39us/step - loss: 7.4359\n",
      "Epoch 54/200\n",
      "30712/30712 [==============================] - 1s 40us/step - loss: 7.4359\n",
      "Epoch 55/200\n",
      "30712/30712 [==============================] - 1s 42us/step - loss: 7.4359\n",
      "Epoch 56/200\n",
      "30712/30712 [==============================] - 2s 50us/step - loss: 7.4359\n",
      "Epoch 57/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359: 0s - l\n",
      "Epoch 58/200\n",
      "30712/30712 [==============================] - 1s 39us/step - loss: 7.4359\n",
      "Epoch 59/200\n",
      "30712/30712 [==============================] - 1s 40us/step - loss: 7.4359\n",
      "Epoch 60/200\n",
      "30712/30712 [==============================] - 1s 41us/step - loss: 7.4359\n",
      "Epoch 61/200\n",
      "30712/30712 [==============================] - 1s 42us/step - loss: 7.4359\n",
      "Epoch 62/200\n",
      "30712/30712 [==============================] - 1s 42us/step - loss: 7.4359\n",
      "Epoch 63/200\n",
      "30712/30712 [==============================] - 1s 40us/step - loss: 7.4359\n",
      "Epoch 64/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 65/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 66/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 67/200\n",
      "30712/30712 [==============================] - 1s 40us/step - loss: 7.4359\n",
      "Epoch 68/200\n",
      "30712/30712 [==============================] - 1s 42us/step - loss: 7.4359\n",
      "Epoch 69/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 70/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 71/200\n",
      "30712/30712 [==============================] - 1s 42us/step - loss: 7.4359\n",
      "Epoch 72/200\n",
      "30712/30712 [==============================] - 1s 39us/step - loss: 7.4359\n",
      "Epoch 73/200\n",
      "30712/30712 [==============================] - 1s 42us/step - loss: 7.4359\n",
      "Epoch 74/200\n",
      "30712/30712 [==============================] - 1s 46us/step - loss: 7.4359\n",
      "Epoch 75/200\n",
      "30712/30712 [==============================] - 1s 47us/step - loss: 7.4359\n",
      "Epoch 76/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 77/200\n",
      "30712/30712 [==============================] - 1s 42us/step - loss: 7.4359\n",
      "Epoch 78/200\n",
      "30712/30712 [==============================] - 1s 45us/step - loss: 7.4359\n",
      "Epoch 79/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 80/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 81/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 82/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 83/200\n",
      "30712/30712 [==============================] - 1s 41us/step - loss: 7.4359\n",
      "Epoch 84/200\n",
      "30712/30712 [==============================] - 1s 42us/step - loss: 7.4359\n",
      "Epoch 85/200\n",
      "30712/30712 [==============================] - 1s 42us/step - loss: 7.4359\n",
      "Epoch 86/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 87/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 88/200\n",
      "30712/30712 [==============================] - 1s 41us/step - loss: 7.4359\n",
      "Epoch 89/200\n",
      "30712/30712 [==============================] - 1s 42us/step - loss: 7.4359\n",
      "Epoch 90/200\n",
      "30712/30712 [==============================] - 1s 42us/step - loss: 7.4359\n",
      "Epoch 91/200\n",
      "30712/30712 [==============================] - 1s 41us/step - loss: 7.4359\n",
      "Epoch 92/200\n",
      "30712/30712 [==============================] - 1s 38us/step - loss: 7.4359\n",
      "Epoch 93/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 94/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30712/30712 [==============================] - 1s 38us/step - loss: 7.4359\n",
      "Epoch 95/200\n",
      "30712/30712 [==============================] - 1s 37us/step - loss: 7.4359\n",
      "Epoch 96/200\n",
      "30712/30712 [==============================] - 1s 41us/step - loss: 7.4359\n",
      "Epoch 97/200\n",
      "30712/30712 [==============================] - 1s 41us/step - loss: 7.4359\n",
      "Epoch 98/200\n",
      "30712/30712 [==============================] - 1s 41us/step - loss: 7.4359\n",
      "Epoch 99/200\n",
      "30712/30712 [==============================] - 1s 42us/step - loss: 7.4359\n",
      "Epoch 100/200\n",
      "30712/30712 [==============================] - 1s 41us/step - loss: 7.4359\n",
      "Epoch 101/200\n",
      "30712/30712 [==============================] - 1s 42us/step - loss: 7.4359\n",
      "Epoch 102/200\n",
      "30712/30712 [==============================] - 1s 42us/step - loss: 7.4359\n",
      "Epoch 103/200\n",
      "30712/30712 [==============================] - 1s 42us/step - loss: 7.4359\n",
      "Epoch 104/200\n",
      "30712/30712 [==============================] - 1s 42us/step - loss: 7.4359\n",
      "Epoch 105/200\n",
      "30712/30712 [==============================] - 1s 41us/step - loss: 7.4359\n",
      "Epoch 106/200\n",
      "30712/30712 [==============================] - 1s 42us/step - loss: 7.4359\n",
      "Epoch 107/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 108/200\n",
      "30712/30712 [==============================] - 1s 40us/step - loss: 7.4359\n",
      "Epoch 109/200\n",
      "30712/30712 [==============================] - 1s 38us/step - loss: 7.4359\n",
      "Epoch 110/200\n",
      "30712/30712 [==============================] - 1s 38us/step - loss: 7.4359\n",
      "Epoch 111/200\n",
      "30712/30712 [==============================] - 1s 38us/step - loss: 7.4359\n",
      "Epoch 112/200\n",
      "30712/30712 [==============================] - 1s 40us/step - loss: 7.4359\n",
      "Epoch 113/200\n",
      "30712/30712 [==============================] - 1s 38us/step - loss: 7.4359\n",
      "Epoch 114/200\n",
      "30712/30712 [==============================] - 1s 39us/step - loss: 7.4359\n",
      "Epoch 115/200\n",
      "30712/30712 [==============================] - 1s 39us/step - loss: 7.4359\n",
      "Epoch 116/200\n",
      "30712/30712 [==============================] - 1s 39us/step - loss: 7.4359\n",
      "Epoch 117/200\n",
      "30712/30712 [==============================] - 1s 40us/step - loss: 7.4359\n",
      "Epoch 118/200\n",
      "30712/30712 [==============================] - 1s 38us/step - loss: 7.4359\n",
      "Epoch 119/200\n",
      "30712/30712 [==============================] - 1s 38us/step - loss: 7.4359\n",
      "Epoch 120/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 121/200\n",
      "30712/30712 [==============================] - 1s 42us/step - loss: 7.4359\n",
      "Epoch 122/200\n",
      "30712/30712 [==============================] - 1s 45us/step - loss: 7.4359\n",
      "Epoch 123/200\n",
      "30712/30712 [==============================] - 1s 47us/step - loss: 7.4359\n",
      "Epoch 124/200\n",
      "30712/30712 [==============================] - 1s 40us/step - loss: 7.4359\n",
      "Epoch 125/200\n",
      "30712/30712 [==============================] - 1s 40us/step - loss: 7.4359\n",
      "Epoch 126/200\n",
      "30712/30712 [==============================] - 1s 39us/step - loss: 7.4359: 0s \n",
      "Epoch 127/200\n",
      "30712/30712 [==============================] - 1s 41us/step - loss: 7.4359\n",
      "Epoch 128/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 129/200\n",
      "30712/30712 [==============================] - 1s 38us/step - loss: 7.4359\n",
      "Epoch 130/200\n",
      "30712/30712 [==============================] - 1s 38us/step - loss: 7.4359: 0s - l\n",
      "Epoch 131/200\n",
      "30712/30712 [==============================] - 1s 38us/step - loss: 7.4359\n",
      "Epoch 132/200\n",
      "30712/30712 [==============================] - 1s 38us/step - loss: 7.4359\n",
      "Epoch 133/200\n",
      "30712/30712 [==============================] - 1s 38us/step - loss: 7.4359\n",
      "Epoch 134/200\n",
      "30712/30712 [==============================] - 1s 45us/step - loss: 7.4359\n",
      "Epoch 135/200\n",
      "30712/30712 [==============================] - 1s 41us/step - loss: 7.4359\n",
      "Epoch 136/200\n",
      "30712/30712 [==============================] - 1s 38us/step - loss: 7.4359\n",
      "Epoch 137/200\n",
      "30712/30712 [==============================] - 1s 37us/step - loss: 7.4359\n",
      "Epoch 138/200\n",
      "30712/30712 [==============================] - 1s 37us/step - loss: 7.4359\n",
      "Epoch 139/200\n",
      "30712/30712 [==============================] - 1s 38us/step - loss: 7.4359\n",
      "Epoch 140/200\n",
      "30712/30712 [==============================] - 1s 39us/step - loss: 7.4359\n",
      "Epoch 141/200\n",
      "30712/30712 [==============================] - 1s 45us/step - loss: 7.4359\n",
      "Epoch 142/200\n",
      "30712/30712 [==============================] - 1s 41us/step - loss: 7.4359\n",
      "Epoch 143/200\n",
      "30712/30712 [==============================] - 1s 38us/step - loss: 7.4359\n",
      "Epoch 144/200\n",
      "30712/30712 [==============================] - 1s 46us/step - loss: 7.4359\n",
      "Epoch 145/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 146/200\n",
      "30712/30712 [==============================] - 1s 41us/step - loss: 7.4359\n",
      "Epoch 147/200\n",
      "30712/30712 [==============================] - 1s 42us/step - loss: 7.4359\n",
      "Epoch 148/200\n",
      "30712/30712 [==============================] - 1s 41us/step - loss: 7.4359\n",
      "Epoch 149/200\n",
      "30712/30712 [==============================] - 1s 41us/step - loss: 7.4359\n",
      "Epoch 150/200\n",
      "30712/30712 [==============================] - 2s 53us/step - loss: 7.4359: 0s - lo - ETA: 0s - loss: 7.\n",
      "Epoch 151/200\n",
      "30712/30712 [==============================] - 1s 45us/step - loss: 7.4359\n",
      "Epoch 152/200\n",
      "30712/30712 [==============================] - 1s 45us/step - loss: 7.4359\n",
      "Epoch 153/200\n",
      "30712/30712 [==============================] - 1s 45us/step - loss: 7.4359\n",
      "Epoch 154/200\n",
      "30712/30712 [==============================] - 1s 45us/step - loss: 7.4359\n",
      "Epoch 155/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 156/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 157/200\n",
      "30712/30712 [==============================] - 1s 46us/step - loss: 7.4359\n",
      "Epoch 158/200\n",
      "30712/30712 [==============================] - 1s 45us/step - loss: 7.4359\n",
      "Epoch 159/200\n",
      "30712/30712 [==============================] - 1s 46us/step - loss: 7.4359\n",
      "Epoch 160/200\n",
      "30712/30712 [==============================] - 1s 42us/step - loss: 7.4359\n",
      "Epoch 161/200\n",
      "30712/30712 [==============================] - 1s 45us/step - loss: 7.4359\n",
      "Epoch 162/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 163/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 164/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 165/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 166/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 167/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 168/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 169/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 170/200\n",
      "30712/30712 [==============================] - 1s 46us/step - loss: 7.4359\n",
      "Epoch 171/200\n",
      "30712/30712 [==============================] - 1s 45us/step - loss: 7.4359\n",
      "Epoch 172/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 173/200\n",
      "30712/30712 [==============================] - 1s 46us/step - loss: 7.4359\n",
      "Epoch 174/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 175/200\n",
      "30712/30712 [==============================] - 1s 42us/step - loss: 7.4359\n",
      "Epoch 176/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 177/200\n",
      "30712/30712 [==============================] - 1s 46us/step - loss: 7.4359\n",
      "Epoch 178/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 179/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 180/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 181/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 182/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 183/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 184/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 185/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30712/30712 [==============================] - 1s 47us/step - loss: 7.4359\n",
      "Epoch 186/200\n",
      "30712/30712 [==============================] - 1s 46us/step - loss: 7.4359: 0s - l\n",
      "Epoch 187/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 188/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 189/200\n",
      "30712/30712 [==============================] - 1s 44us/step - loss: 7.4359\n",
      "Epoch 190/200\n",
      "30712/30712 [==============================] - 1s 42us/step - loss: 7.4359: 0s - loss: 7\n",
      "Epoch 191/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 192/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359: 0s - loss\n",
      "Epoch 193/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 194/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 195/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 196/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 197/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 198/200\n",
      "30712/30712 [==============================] - 1s 43us/step - loss: 7.4359\n",
      "Epoch 199/200\n",
      "30712/30712 [==============================] - 1s 46us/step - loss: 7.4359\n",
      "Epoch 200/200\n",
      "30712/30712 [==============================] - 1s 46us/step - loss: 7.4359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22c6ad83ac8>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "############# This found the best output\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(100, input_shape=(52,)),\n",
    "    Activation('softmax'),\n",
    "    Dense(40),\n",
    "    Activation('sigmoid'),\n",
    "    Dense(1),\n",
    "    Activation('relu')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='mean_absolute_error')\n",
    "\n",
    "model.fit(train_x2, train_y, epochs=200, batch_size=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing output to  ../Predictions/bestbest.csv\n",
      "Done with writing.\n"
     ]
    }
   ],
   "source": [
    "predicted_y=model.predict(kaggle_x2)\n",
    "predicted_y=predicted_y.clip(min=0)\n",
    "file_name = '../Predictions/bestbest.csv'\n",
    "# Writing output in Kaggle format\n",
    "print('Writing output to ', file_name)\n",
    "kaggle.kaggleize(predicted_y, file_name)\n",
    "print('Done with writing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-122-9ed1335c162b>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-122-9ed1335c162b>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    p_grid = {'hidden_layer_sizes':[(1:2),(2:3)]}\u001b[0m\n\u001b[1;37m                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "### Question 6\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "mynnk=MLPRegressor(max_iter=400)\n",
    "p_grid = {'hidden_layer_sizes':[(40,60,80,100),(10,20,30,40)]}\n",
    "bestnnk = GridSearchCV(estimator=mynnk, param_grid=p_grid, cv=10,return_train_score=True,scoring='neg_mean_absolute_error')\n",
    "bestnnk.fit(train_x2,train_y)\n",
    "print(\"Done with CV on NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(bestnn.best_params_)\n",
    "bestnnk.fit(train_x2,train_y)\n",
    "predicted_y=bestnnk.predict(kaggle_x2)\n",
    "predicted_y=predicted_y.clip(min=0)\n",
    "file_name = '../Predictions/bestnn.csv'\n",
    "# Writing output in Kaggle format\n",
    "print('Writing output to ', file_name)\n",
    "kaggle.kaggleize(predicted_y, file_name)\n",
    "print('Done with writing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-123-efff9d70dff8>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-123-efff9d70dff8>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    [(1:2),(2:3)]\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "[(1:2),(2:3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-128-a8a0d2465165>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-128-a8a0d2465165>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    type([1:2])\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "a=[(1,2),(2,3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-129-0f96395e9759>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-129-0f96395e9759>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    [1:2]\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "[1:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-132-973377ee365f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-132-973377ee365f>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    (1:1:3)\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "(1:1:3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
